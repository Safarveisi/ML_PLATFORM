name: Update Mlflow Artifact Path and Deploy on Kserve

on:
  push:
    branches:
      - master
env:
  best_model_directory: ml_platform/best_model_artifacts
  mlflow_artifactory_prefix: ml_platform/mlartifacts

jobs:
  mlflow-environment-artifact:
    runs-on: ubuntu-24.04
    steps:
      - name: Check Out Code
        uses: actions/checkout@v4
      
      - name: Load .env file
        uses: xom9ikk/dotenv@v2.3.0
        with:
          path: ./${{ env.best_model_directory }}
          mode: best_run
          load-mode: strict

      - name: Set up miniconda
        uses: conda-incubator/setup-miniconda@v3
        with: 
          auto-activate-base: false
          channels: conda-forge,defaults
          environment-file: ${{ env.best_model_directory }}/conda.yaml
          activate-environment: mlflow-env

      # Step 1: Create the environment tarball
      - name: Make a Tarball of the Environment
        working-directory: ${{ env.best_model_directory }}
        shell: bash -l {0}
        env:
          EXPERIMENT_ID: ${{ env.EXPERIMENT_ID }}
          RUN_ID: ${{ env.RUN_ID }}
        run: |
          conda-pack -o environment.tar.gz -f

      - name: Upload environment.tar.gz to S3
        uses: ./actions/s3cmd-docker
        with:
          command: "put environment.tar.gz s3://customerintelligence/${{ env.mlflow_artifactory_prefix }}/${{ env.EXPERIMENT_ID }}/${{ env.RUN_ID }}/artifacts/iris_xgb/environment.tar.gz"
          access-key: ${{ secrets.AWS_ACCESS_KEY_ID }}
          secret-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          endpoint-url: ${{ secrets.S3_ENDPOINT_URL }}
          bucket-location: ${{ secrets.BUCKET_LOCATION }}
                 
            
            
